{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8123821",
   "metadata": {},
   "source": [
    "\n",
    "# Taxi Cohort + Tail Modeling Dashboard\n",
    "\n",
    "Interactive notebook that merges the cohort explorer and the Poisson vs. Neg-Bin tail demo so you can:\n",
    "- Load a slice of NYC Yellow Taxi data with zone metadata.\n",
    "- Filter by weekday/weekend and rush/off-peak cohorts.\n",
    "- Inspect arrival histograms and dispersion per zone/bucket.\n",
    "- Compare empirical tails vs. Poisson/NB tail approximations with classic bounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7910b",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "Run the cell below if the plotting/widget dependencies are missing in your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf96d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet plotly pandas numpy ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccffd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from scipy.stats import poisson as sp_poisson, nbinom as sp_nbinom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcaed586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src/ to path for project helpers\n",
    "root = Path.cwd().resolve()\n",
    "for candidate in [root, *root.parents]:\n",
    "    if (candidate / 'src').exists():\n",
    "        sys.path.append(str(candidate / 'src'))\n",
    "        break\n",
    "from modeling.poisson_zone import load_taxi_pickups, attach_zone_metadata, bucket_counts_by_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325b8cd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9a4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXI_PATH = Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-01.parquet')\n",
    "LOOKUP_CSV = Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/taxi_zone_lookup.csv')\n",
    "MAX_ROWS = 4_000_000\n",
    "BUCKET_BASE = '15min'\n",
    "MIN_MEAN = 1.0\n",
    "MIN_NONZERO = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14877fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUSH_RANGES = [(7, 10), (16, 19)]  # inclusive start, exclusive end\n",
    "\n",
    "def is_rush(hour, ranges=RUSH_RANGES):\n",
    "    return any(lo <= hour < hi for lo, hi in ranges)\n",
    "\n",
    "def cohort_label(is_weekend: pd.Series, is_rush: pd.Series) -> pd.Series:\n",
    "    weekend = np.where(is_weekend, 'weekend', 'weekday')\n",
    "    rush = np.where(is_rush, 'rush', 'offpeak')\n",
    "    return pd.Series(weekend + '_' + rush, index=is_weekend.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004ba78",
   "metadata": {},
   "source": [
    "## Load taxi sample & derive cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e635659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,954,264 trips across 258 zones\n"
     ]
    }
   ],
   "source": [
    "if not TAXI_PATH.exists():\n",
    "    raise FileNotFoundError(TAXI_PATH)\n",
    "if not LOOKUP_CSV.exists():\n",
    "    raise FileNotFoundError(LOOKUP_CSV)\n",
    "\n",
    "trips = load_taxi_pickups(TAXI_PATH, max_rows=MAX_ROWS)\n",
    "trips = attach_zone_metadata(trips, LOOKUP_CSV).dropna(subset=['Zone'])\n",
    "trips['event_time'] = trips['event_time'].dt.tz_convert(None)\n",
    "trips['hour'] = trips['event_time'].dt.hour\n",
    "trips['is_weekend'] = trips['event_time'].dt.dayofweek >= 5\n",
    "trips['is_rush'] = trips['hour'].apply(is_rush)\n",
    "trips['cohort'] = cohort_label(trips['is_weekend'], trips['is_rush'])\n",
    "trips['bucket_start'] = trips['event_time'].dt.floor(BUCKET_BASE)\n",
    "\n",
    "print(f\"Loaded {len(trips):,} trips across {trips['Zone'].nunique()} zones\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28fca824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active zones: 58 | Cohorts: ['weekday_offpeak', 'weekday_rush', 'weekend_offpeak', 'weekend_rush']\n"
     ]
    }
   ],
   "source": [
    "# Screen for active zones and prep cohort-level counts\n",
    "base_counts = bucket_counts_by_group(trips, freq=BUCKET_BASE, group_cols='Zone')\n",
    "means = base_counts.mean()\n",
    "nonzero = (base_counts > 0).mean()\n",
    "active_zones = [z for z in base_counts.columns if means[z] >= MIN_MEAN and nonzero[z] >= MIN_NONZERO]\n",
    "active_zones = sorted(active_zones) or sorted(trips['Zone'].unique())\n",
    "\n",
    "cohort_counts = (\n",
    "    trips\n",
    "    .groupby(['Zone', 'cohort', 'bucket_start'])\n",
    "    .size()\n",
    "    .rename('arrivals')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(f\"Active zones: {len(active_zones)} | Cohorts: {sorted(trips['cohort'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2a58f",
   "metadata": {},
   "source": [
    "## Modeling helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17cff635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nb(series: pd.Series):\n",
    "    \"\"\"Method-of-moments NB fit returning (r, p).\"\"\"\n",
    "    mean = series.mean()\n",
    "    var = series.var(ddof=0)\n",
    "    if var <= mean or mean <= 0:\n",
    "        return np.nan, np.nan\n",
    "    r = mean ** 2 / (var - mean)\n",
    "    p = r / (r + mean)\n",
    "    return r, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa95c5",
   "metadata": {},
   "source": [
    "## Tail fit explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704062fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3e1f4735454d438c6066b21f6e9917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Zone', options=('Alphabet City', 'Battery Park City', 'Blo…"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_tail_app():\n",
    "    zone_dd = widgets.Dropdown(options=active_zones, description='Zone')\n",
    "    cohort_opts = ['All trips'] + sorted(trips['cohort'].unique())\n",
    "    cohort_dd = widgets.Dropdown(options=cohort_opts, description='Cohort')\n",
    "    freq_dd = widgets.Dropdown(options=['5min', '15min', '30min', '1H'], value='15min', description='Bucket')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def refresh(*_):\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            cohort = cohort_dd.value\n",
    "            subset = trips if cohort == 'All trips' else trips[trips['cohort'] == cohort]\n",
    "            if subset.empty:\n",
    "                print('No trips for this cohort.')\n",
    "                return\n",
    "            counts = bucket_counts_by_group(subset, freq=freq_dd.value, group_cols='Zone')\n",
    "            if zone_dd.value not in counts.columns:\n",
    "                print('Zone missing for this selection.')\n",
    "                return\n",
    "            series = counts[zone_dd.value]\n",
    "            nonzero_frac = (series > 0).mean()\n",
    "            mean = series.mean()\n",
    "            if mean < MIN_MEAN or nonzero_frac < MIN_NONZERO:\n",
    "                print(f'Selection too sparse (mean={mean:.2f}, nonzero={nonzero_frac:.2f}).')\n",
    "                return\n",
    "            var = series.var(ddof=0)\n",
    "            disp = var / mean if mean > 0 else np.nan\n",
    "            nb_r, nb_p = fit_nb(series)\n",
    "            grid = np.arange(0, max(series.max(), int(series.quantile(0.99)) + 5) + 1)\n",
    "            obs = series.value_counts().reindex(grid, fill_value=0).values\n",
    "            fig = go.Figure()\n",
    "            fig.add_bar(x=grid, y=obs, name='Observed', marker=dict(color='#4B6BFB'), opacity=0.75)\n",
    "            pois_exp = sp_poisson.pmf(grid, mean) * len(series)\n",
    "            fig.add_scatter(x=grid, y=pois_exp, mode='lines', name='Poisson', line=dict(color='#FFA500', width=2))\n",
    "            if np.isfinite(nb_r) and np.isfinite(nb_p) and nb_r > 0 and 0 < nb_p < 1:\n",
    "                nb_exp = sp_nbinom.pmf(grid, nb_r, nb_p) * len(series)\n",
    "                fig.add_scatter(x=grid, y=nb_exp, mode='lines', name='Neg-Bin', line=dict(color='#D62728', width=3))\n",
    "            fig.update_layout(title=f\"{zone_dd.value} ({freq_dd.value}) — {cohort_dd.value}\", xaxis_title='Arrivals per bucket', yaxis_title='Frequency', template='plotly_white')\n",
    "            fig.show()\n",
    "            summary = {\n",
    "                'zone': zone_dd.value,\n",
    "                'cohort': cohort_dd.value,\n",
    "                'freq': freq_dd.value,\n",
    "                'mean': mean,\n",
    "                'variance': var,\n",
    "                'dispersion': disp,\n",
    "            }\n",
    "            display(pd.DataFrame([summary]))\n",
    "\n",
    "    zone_dd.observe(refresh, names='value')\n",
    "    cohort_dd.observe(refresh, names='value')\n",
    "    freq_dd.observe(refresh, names='value')\n",
    "\n",
    "    refresh()\n",
    "    return widgets.VBox([widgets.HBox([zone_dd, cohort_dd]), freq_dd, out])\n",
    "\n",
    "tail_app = build_tail_app()\n",
    "tail_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ed873",
   "metadata": {},
   "source": [
    "## Cohort histogram explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb5f6a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd63b06b0e247deaa71a93cf4c39dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Zone', options=('Allerton/Pelham Gardens', 'Alphabet City'…"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_hist_app():\n",
    "    zones = sorted(trips['Zone'].unique())\n",
    "    cohorts = sorted(trips['cohort'].unique())\n",
    "    zone_dd = widgets.Dropdown(options=zones, description='Zone')\n",
    "    cohort_dd = widgets.Dropdown(options=cohorts, description='Cohort')\n",
    "    bucket_dd = widgets.Dropdown(options=['5min', '15min', '30min', '1H'], value=BUCKET_BASE, description='Bucket')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def refresh(*_):\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            sub = cohort_counts[(cohort_counts['Zone'] == zone_dd.value) & (cohort_counts['cohort'] == cohort_dd.value)]\n",
    "            if sub.empty:\n",
    "                print('No data for this zone/cohort.')\n",
    "                return\n",
    "            bucket = bucket_dd.value\n",
    "            stacks = sub.copy()\n",
    "            stacks['bucket_start'] = stacks['bucket_start'].dt.floor(bucket)\n",
    "            agg = stacks.groupby('bucket_start')['arrivals'].sum().reset_index()\n",
    "            stats = agg['arrivals'].describe(percentiles=[0.5, 0.9]).to_frame().T\n",
    "            fig = px.histogram(agg, x='arrivals', nbins=40, title=f\"{zone_dd.value} / {cohort_dd.value} ({bucket})\")\n",
    "            fig.update_layout(xaxis_title='Arrivals per bucket', yaxis_title='Frequency')\n",
    "            fig.show()\n",
    "            display(stats[['mean', 'std', 'min', '50%', '90%', 'max']])\n",
    "\n",
    "    zone_dd.observe(refresh, names='value')\n",
    "    cohort_dd.observe(refresh, names='value')\n",
    "    bucket_dd.observe(refresh, names='value')\n",
    "\n",
    "    refresh()\n",
    "    return widgets.VBox([widgets.HBox([zone_dd, cohort_dd, bucket_dd]), out])\n",
    "\n",
    "hist_app = build_hist_app()\n",
    "hist_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22b911",
   "metadata": {},
   "source": [
    "## Combined dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18429c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe74b205d3940adbd0c37385474f629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HBox(children=(Dropdown(description='Zone', options=('Alphabet City', 'Battery Pa…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabs = widgets.Tab(children=[tail_app, hist_app])\n",
    "tabs.set_title(0, 'Tail fits')\n",
    "tabs.set_title(1, 'Cohort histograms')\n",
    "tabs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
