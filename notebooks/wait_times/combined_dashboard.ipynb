{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ab86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Transit Wait-Time Diagnostic\n",
    "# Unified notebook for exploring Taxi and Citi Bike arrival patterns and wait times\n",
    "\n",
    "# %pip install --quiet plotly pandas numpy ipywidgets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from scipy.stats import poisson as sp_poisson, nbinom as sp_nbinom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea8efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Taxi configuration\n",
    "TAXI_PATHS = [\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-01.parquet'),\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-02.parquet'),\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-03.parquet'),\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-04.parquet'),\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-05.parquet'),\n",
    "    Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/yellow_tripdata_2024-06.parquet'),\n",
    "]\n",
    "LOOKUP_CSV = Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/taxi_zone_lookup.csv')\n",
    "TAXI_MAX_ROWS = 4_0000_000\n",
    "\n",
    "# Bike configuration\n",
    "BIKE_DATA_ROOT = Path('/Users/atharvramesh/UCSD/Fall2025/ECE225A/NYC_Public_Transit/data/raw/citibike')\n",
    "# BIKE_GLOB = '202401-citibike-tripdata_*.csv'\n",
    "BIKE_GLOB = '2024*-citibike-tripdata_*.csv'\n",
    "BIKE_MAX_ROWS = 5_0000_000\n",
    "\n",
    "# Shared configuration\n",
    "BUCKET_BASE = '15min'\n",
    "TAXI_MIN_MEAN = 1.0\n",
    "TAXI_MIN_NONZERO = 0.3\n",
    "BIKE_MIN_MEAN = 0.5\n",
    "BIKE_MIN_NONZERO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee473766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src/ to path for project helpers\n",
    "root = Path.cwd().resolve()\n",
    "for candidate in [root, *root.parents]:\n",
    "    if (candidate / 'src').exists():\n",
    "        sys.path.append(str(candidate / 'src'))\n",
    "        break\n",
    "from modeling.poisson_zone import load_taxi_pickups, attach_zone_metadata, bucket_counts_by_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0c8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Utility Functions\n",
    "# ============================================================================\n",
    "\n",
    "def fit_nb(series: pd.Series):\n",
    "    \"\"\"Method-of-moments NB fit returning (r, p).\"\"\"\n",
    "    mean = series.mean()\n",
    "    var = series.var(ddof=0)\n",
    "    if var <= mean or mean <= 0:\n",
    "        return np.nan, np.nan\n",
    "    r = mean ** 2 / (var - mean)\n",
    "    p = r / (r + mean)\n",
    "    return r, p\n",
    "\n",
    "def is_rush(hour, ranges=[(7, 10), (16, 19)]):\n",
    "    return any(lo <= hour < hi for lo, hi in ranges)\n",
    "\n",
    "def cohort_label(is_weekend: pd.Series, is_rush: pd.Series) -> pd.Series:\n",
    "    weekend = np.where(is_weekend, 'weekend', 'weekday')\n",
    "    rush = np.where(is_rush, 'rush', 'offpeak')\n",
    "    return pd.Series(weekend + '_' + rush, index=is_weekend.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc2c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 6 taxi files...\n",
      "  Reading yellow_tripdata_2024-01.parquet...\n",
      "  Reading yellow_tripdata_2024-02.parquet...\n",
      "  Reading yellow_tripdata_2024-03.parquet...\n",
      "  Reading yellow_tripdata_2024-04.parquet...\n",
      "  Reading yellow_tripdata_2024-05.parquet...\n",
      "  Reading yellow_tripdata_2024-06.parquet...\n",
      "  Concatenating data...\n",
      "Loaded 20,266,415 taxi trips across 61 active zones (Jan-Jun 2024)\n",
      "Loaded 18,795,711 bike trips across 704 active stations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "\n",
    "def load_taxi_data():\n",
    "    \"\"\"Load and prepare taxi data from multiple months.\"\"\"\n",
    "    \n",
    "    print(f\"Loading {len(TAXI_PATHS)} taxi files...\")\n",
    "    frames = []\n",
    "    \n",
    "    for path in TAXI_PATHS:\n",
    "        if not path.exists():\n",
    "            print(f\"  Warning: {path.name} not found, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Reading {path.name}...\")\n",
    "        trips = load_taxi_pickups(path, max_rows=TAXI_MAX_ROWS)\n",
    "        frames.append(trips)\n",
    "    \n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No taxi data files were successfully loaded\")\n",
    "    \n",
    "    # Combine all months\n",
    "    print(\"  Concatenating data...\")\n",
    "    trips = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "    # Process combined data\n",
    "    trips = attach_zone_metadata(trips, LOOKUP_CSV).dropna(subset=['Zone'])\n",
    "    trips['event_time'] = trips['event_time'].dt.tz_convert(None)\n",
    "    trips['month'] = trips['event_time'].dt.month  # Track which month\n",
    "    trips['hour'] = trips['event_time'].dt.hour\n",
    "    trips['is_weekend'] = trips['event_time'].dt.dayofweek >= 5\n",
    "    trips['is_rush'] = trips['hour'].apply(is_rush)\n",
    "    trips['cohort'] = cohort_label(trips['is_weekend'], trips['is_rush'])\n",
    "    trips['bucket_start'] = trips['event_time'].dt.floor(BUCKET_BASE)\n",
    "    \n",
    "    # Screen for active zones\n",
    "    base_counts = bucket_counts_by_group(trips, freq=BUCKET_BASE, group_cols='Zone')\n",
    "    means = base_counts.mean()\n",
    "    nonzero = (base_counts > 0).mean()\n",
    "    active_zones = [z for z in base_counts.columns \n",
    "                    if means[z] >= TAXI_MIN_MEAN and nonzero[z] >= TAXI_MIN_NONZERO]\n",
    "    active_zones = sorted(active_zones) or sorted(trips['Zone'].unique())\n",
    "    \n",
    "    print(f\"Loaded {len(trips):,} taxi trips across {len(active_zones)} active zones (Jan-Jun 2024)\")\n",
    "    return trips, active_zones, 'Zone'\n",
    "\n",
    "def load_bike_data():\n",
    "    \"\"\"Load and prepare Citi Bike data.\"\"\"\n",
    "    files = sorted(BIKE_DATA_ROOT.glob(BIKE_GLOB))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No Citi Bike CSVs matching {BIKE_GLOB}')\n",
    "    \n",
    "    frames = []\n",
    "    for i, f in enumerate(files):\n",
    "        frames.append(pd.read_csv(\n",
    "            f,\n",
    "            nrows=BIKE_MAX_ROWS if (BIKE_MAX_ROWS and i == 0) else None,\n",
    "            dtype={'start_station_id': str, 'end_station_id': str},\n",
    "            low_memory=False,\n",
    "        ))\n",
    "    bike = pd.concat(frames, ignore_index=True)\n",
    "    bike['event_time'] = pd.to_datetime(bike['started_at'])\n",
    "    bike = bike.dropna(subset=['start_station_id', 'start_lat', 'start_lng'])\n",
    "    bike['start_station_id'] = bike['start_station_id'].astype(str)\n",
    "    bike['hour'] = bike['event_time'].dt.hour\n",
    "    bike['is_weekend'] = bike['event_time'].dt.dayofweek >= 5\n",
    "    bike['bucket_start'] = bike['event_time'].dt.floor(BUCKET_BASE)\n",
    "    \n",
    "    def label(row):\n",
    "        weekend = 'weekend' if row['is_weekend'] else 'weekday'\n",
    "        rush = 'rush' if (7 <= row['hour'] < 10) or (16 <= row['hour'] < 19) else 'offpeak'\n",
    "        return f\"{weekend}_{rush}\"\n",
    "    \n",
    "    bike['cohort'] = bike.apply(label, axis=1)\n",
    "    bike = bike.rename(columns={'start_station_id': 'StationID'})\n",
    "    \n",
    "    # Screen for active stations\n",
    "    base_counts = bucket_counts_by_group(bike, freq=BUCKET_BASE, group_cols='StationID')\n",
    "    means = base_counts.mean()\n",
    "    nonzero = (base_counts > 0).mean()\n",
    "    active_stations = [sid for sid in base_counts.columns \n",
    "                       if means[sid] >= BIKE_MIN_MEAN and nonzero[sid] >= BIKE_MIN_NONZERO]\n",
    "    active_stations = sorted(active_stations)\n",
    "    \n",
    "    print(f\"Loaded {len(bike):,} bike trips across {len(active_stations)} active stations\")\n",
    "    return bike, active_stations, 'StationID'\n",
    "\n",
    "# Load data\n",
    "taxi_trips, taxi_zones, taxi_group_col = load_taxi_data()\n",
    "bike_trips, bike_stations, bike_group_col = load_bike_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22381168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dashboard Creation\n",
    "# ============================================================================\n",
    "\n",
    "def create_combined_figure(series, mean, var, nb_r, nb_p, diffs, wait_mean, title_prefix):\n",
    "    \"\"\"Create a 2-subplot figure with arrivals and wait times.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Arrivals per Bucket', 'Wait Time Distribution'),\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Left plot: Arrival counts\n",
    "    grid = np.arange(0, max(series.max(), int(series.quantile(0.99)) + 5) + 1)\n",
    "    obs = series.value_counts().reindex(grid, fill_value=0).values\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=grid, y=obs, name='Observed', \n",
    "                         marker=dict(color='#4B6BFB'), opacity=0.75), row=1, col=1)\n",
    "    \n",
    "    pois_exp = sp_poisson.pmf(grid, mean) * len(series)\n",
    "    fig.add_trace(go.Scatter(x=grid, y=pois_exp, mode='lines', name='Poisson',\n",
    "                            line=dict(color='#FFA500', width=2)), row=1, col=1)\n",
    "    \n",
    "    if np.isfinite(nb_r) and np.isfinite(nb_p) and nb_r > 0 and 0 < nb_p < 1:\n",
    "        nb_exp = sp_nbinom.pmf(grid, nb_r, nb_p) * len(series)\n",
    "        fig.add_trace(go.Scatter(x=grid, y=nb_exp, mode='lines', name='Neg-Bin',\n",
    "                                line=dict(color='#D62728', width=3)), row=1, col=1)\n",
    "    \n",
    "    # Right plot: Wait times\n",
    "    if not diffs.empty and wait_mean > 0:\n",
    "        fig.add_trace(go.Histogram(x=diffs, nbinsx=100, name='Empirical Wait',\n",
    "                                   marker=dict(color='#4B6BFB'), opacity=0.75,\n",
    "                                   histnorm='probability density'), row=1, col=2)\n",
    "        \n",
    "        lam = 1 / wait_mean\n",
    "        x = np.linspace(0, diffs.max(), 200)\n",
    "        pdf = lam * np.exp(-lam * x)\n",
    "        fig.add_trace(go.Scatter(x=x, y=pdf, mode='lines', name='Exponential',\n",
    "                                line=dict(color=\"#99FF00\", width=2)), row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Arrivals', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Frequency', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Minutes', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Density', row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=450, \n",
    "        showlegend=True, \n",
    "        template='plotly_white',\n",
    "        title_text=title_prefix,\n",
    "        title_x=0.5,\n",
    "        title_xanchor='center'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def build_dashboard(trips_data, locations, group_col, min_mean, min_nonzero, title):\n",
    "    \"\"\"Build a dashboard for either taxi or bike data.\"\"\"\n",
    "    location_dd = widgets.Dropdown(options=locations, description='Location')\n",
    "    cohort_opts = ['All trips'] + sorted(trips_data['cohort'].unique())\n",
    "    cohort_dd = widgets.Dropdown(options=cohort_opts, description='Cohort')\n",
    "    freq_dd = widgets.Dropdown(options=['5min','15min','30min','1H'], value='15min', description='Bucket')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def refresh():\n",
    "        out.clear_output(wait=True)\n",
    "        with out:\n",
    "            cohort = cohort_dd.value\n",
    "            subset = trips_data if cohort == 'All trips' else trips_data[trips_data['cohort'] == cohort]\n",
    "            \n",
    "            if subset.empty:\n",
    "                print('No trips for this cohort selection.')\n",
    "                return\n",
    "            \n",
    "            counts = bucket_counts_by_group(subset, freq=freq_dd.value, group_cols=group_col)\n",
    "            \n",
    "            if location_dd.value not in counts.columns:\n",
    "                print('Location missing for this selection.')\n",
    "                return\n",
    "            \n",
    "            series = counts[location_dd.value]\n",
    "            nonzero_frac = (series > 0).mean()\n",
    "            mean = series.mean()\n",
    "            \n",
    "            if mean < min_mean or nonzero_frac < min_nonzero:\n",
    "                print(f'Selection too sparse (mean={mean:.2f}, nonzero={nonzero_frac:.2f}).')\n",
    "                return\n",
    "            \n",
    "            var = series.var(ddof=0)\n",
    "            disp = var / mean if mean > 0 else np.nan\n",
    "            nb_r, nb_p = fit_nb(series)\n",
    "            \n",
    "            # Calculate wait times\n",
    "            location_subset = subset[subset[group_col] == location_dd.value].sort_values('event_time')\n",
    "            diffs = location_subset['event_time'].diff().dropna().dt.total_seconds() / 60\n",
    "            diffs = diffs[(diffs > 0) & (diffs < 180)]\n",
    "            wait_mean = diffs.mean() if not diffs.empty else 0\n",
    "            \n",
    "            # Create combined figure\n",
    "            fig = create_combined_figure(series, mean, var, nb_r, nb_p, diffs, wait_mean,\n",
    "                                        f\"{location_dd.value} ({cohort}, {freq_dd.value})\")\n",
    "            display(fig)\n",
    "            \n",
    "            # Summary statistics\n",
    "            summary = pd.DataFrame([{\n",
    "                'location': location_dd.value,\n",
    "                'cohort': cohort,\n",
    "                'freq': freq_dd.value,\n",
    "                'mean_arrivals': mean,\n",
    "                'variance': var,\n",
    "                'dispersion': disp,\n",
    "                'nb_r': nb_r,\n",
    "                'nb_p': nb_p,\n",
    "                'mean_wait_min': wait_mean if not diffs.empty else np.nan\n",
    "            }])\n",
    "            display(summary)\n",
    "\n",
    "    location_dd.observe(lambda _: refresh(), names='value')\n",
    "    cohort_dd.observe(lambda _: refresh(), names='value')\n",
    "    freq_dd.observe(lambda _: refresh(), names='value')\n",
    "    \n",
    "    refresh()\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(f\"<h3>{title}</h3>\"),\n",
    "        widgets.HBox([location_dd, cohort_dd]),\n",
    "        freq_dd,\n",
    "        out\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908a5f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ac3cc0cf2041d69e2a9b8c6012f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='<h3>ðŸš• Taxi Dashboard</h3>'), HBox(children=(Dropdown(description='Locâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Main Dashboard with Tabs\n",
    "# ============================================================================\n",
    "\n",
    "taxi_dashboard = build_dashboard(taxi_trips, taxi_zones, taxi_group_col, \n",
    "                                 TAXI_MIN_MEAN, TAXI_MIN_NONZERO, \"ðŸš• Taxi Dashboard\")\n",
    "bike_dashboard = build_dashboard(bike_trips, bike_stations, bike_group_col,\n",
    "                                 BIKE_MIN_MEAN, BIKE_MIN_NONZERO, \"ðŸš² Bike Dashboard\")\n",
    "\n",
    "tabs = widgets.Tab(children=[taxi_dashboard, bike_dashboard])\n",
    "tabs.set_title(0, 'Taxi')\n",
    "tabs.set_title(1, 'Citi Bike')\n",
    "\n",
    "display(tabs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
